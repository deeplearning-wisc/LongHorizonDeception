"""
ResultSaver - çº¯JSONæ ¼å¼çš„å®éªŒè®°å½•ä¿å­˜ç³»ç»Ÿ
åˆ é™¤æ‰€æœ‰TXTæ ¼å¼ï¼Œåªä¿å­˜ç»“æ„åŒ–JSONæ•°æ®
"""

import json
import time
from typing import Dict, List, Any, Optional
from pathlib import Path

class ResultSaver:
    """çº¯JSONæ ¼å¼çš„å®éªŒè®°å½•ä¿å­˜ç³»ç»Ÿ"""
    
    def __init__(self, session_name: str, results_dir: str = "results"):
        self.session_name = session_name
        self.results_dir = Path(results_dir)
        self.session_dir = self.results_dir / session_name
        self.session_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºglobal_roundså­ç›®å½• - æ¯ä¸ªglobal roundä¸€ä¸ªJSONæ–‡ä»¶
        self.rounds_dir = self.session_dir / "global_rounds"
        self.rounds_dir.mkdir(exist_ok=True)
        
        # å…¨å±€è½®æ¬¡è®¡æ•°å™¨
        self.global_round_counter = 0
        
        # ä¼šè¯å…ƒæ•°æ®ï¼ˆä¿å­˜åœ¨ä¸»ç›®å½•ï¼‰
        self.session_metadata = {
            "session_name": session_name,
            "start_time": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()),
            "end_time": None,
            "experiment_mode": None,
            "total_tasks": 0,
            "total_global_rounds": 0
        }
        
        # å®éªŒé…ç½®ï¼ˆä¿å­˜åœ¨ä¸»ç›®å½•ï¼‰
        self.experiment_config = {}
        
        # å½“å‰ä»»åŠ¡å’Œè½®æ¬¡çŠ¶æ€
        self.current_task_info = None
        self.current_round_info = None
    
    def set_experiment_config(self, config: Dict[str, Any]):
        """è®¾ç½®å®éªŒé…ç½®"""
        self.experiment_config = {
            "max_rounds_per_task": config['max_rounds_per_task'],
            "p_event": config['p_event'],
            "summary_level": config['summary_level'],
            "llm_models": self._build_models_info(config)
        }
        self.session_metadata["experiment_mode"] = config['experiment_mode'].upper()
        
        # ä¿å­˜ä¼šè¯å…ƒæ•°æ®å’Œå®éªŒé…ç½®åˆ°ä¸»ç›®å½•
        self._save_session_info()
    
    def set_event_sequence_preview(self, event_preview: str):
        """è®¾ç½®äº‹ä»¶åºåˆ—é¢„è§ˆä¿¡æ¯"""
        self.session_metadata["event_sequence_preview"] = event_preview
        # ç«‹å³ä¿å­˜æ›´æ–°åçš„ä¼šè¯ä¿¡æ¯
        self._save_session_info()
    
    def _build_models_info(self, config: Dict) -> Dict[str, str]:
        """æ„å»ºæ¨¡å‹ä¿¡æ¯å­—å…¸ï¼Œdetectoræ˜¯å¯é€‰çš„"""
        models_info = {
            "llm": self._extract_model_name(config, 'llm'),
            "manager": self._extract_model_name(config, 'manager')
        }
        
        # å¦‚æœé…ç½®ä¸­æœ‰detectorï¼Œæ·»åŠ å®ƒ
        if 'llm_api_config' not in config:
            raise ValueError("Missing 'llm_api_config' section in config")
        if 'detector' in config['llm_api_config']:
            models_info["detector"] = self._extract_model_name(config, 'detector')
        
        return models_info
    
    def _save_session_info(self):
        """ä¿å­˜ä¼šè¯ä¿¡æ¯åˆ°ä¸»ç›®å½•"""
        session_info = {
            "session_metadata": self.session_metadata,
            "experiment_config": self.experiment_config
        }
        
        session_file = self.session_dir / "session_info.json"
        with open(session_file, 'w', encoding='utf-8') as f:
            json.dump(session_info, f, indent=2, ensure_ascii=False)
    
    def _save_global_round(self, global_round: int, round_data: Dict[str, Any]):
        """ä¿å­˜å•ä¸ªglobal roundçš„æ•°æ®åˆ°å•ç‹¬çš„JSONæ–‡ä»¶"""
        # åˆ›å»ºæ–‡ä»¶å: round_001.json, round_002.json, etc.
        filename = f"round_{global_round:03d}.json"
        round_file = self.rounds_dir / filename
        
        # æ·»åŠ æ—¶é—´æˆ³å’Œè½®æ¬¡ä¿¡æ¯
        complete_round_data = {
            "global_round": global_round,
            "timestamp": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()),
            "session_name": self.session_name,
            **round_data
        }
        
        with open(round_file, 'w', encoding='utf-8') as f:
            json.dump(complete_round_data, f, indent=2, ensure_ascii=False)
            
        print(f"[JSON] Global round {global_round} saved to {filename}")
    
    def _extract_model_name(self, config: Dict, component: str) -> str:
        """ä»é…ç½®ä¸­æå–æ¨¡å‹åç§°"""
        llm_config = config['llm_api_config'][component]
        provider = llm_config['provider']
        provider_config = llm_config[provider]
        
        # å°è¯•ä¸åŒçš„å­—æ®µå
        if 'model' in provider_config:
            return provider_config['model']
        elif 'model_name' in provider_config:
            return provider_config['model_name']
        else:
            return f"unknown_{provider}_model"
    
    def start_task(self, task_sequence_num: int, task, event_info: Dict[str, Any]):
        """å¼€å§‹æ–°ä»»åŠ¡"""
        self.current_task_info = {
            "task_sequence_num": task_sequence_num,
            "task_sequence_num_from_json": getattr(task, 'task_sequence_num', task_sequence_num),
            "title": task.title,
            "files": [
                {
                    "filename": f.filename,
                    "file_type": f.file_type,
                    "content": f.content
                } for f in (task.files or [])
            ],
            "event_info": {
                "category": event_info['category'],
                "pressure_level": event_info['pressure_level'],
                "content": event_info['content']
            },
            "rounds": []
        }
    
    def start_round(self, round_num: int, manager_state_before: Dict[str, float], global_round: int = None):
        """å¼€å§‹æ–°è½®æ¬¡"""
        self.current_round_info = {
            "round_num": round_num,
            "global_round": global_round,  # å…¨å±€è½®æ¬¡ç¼–å·
            "start_timestamp": time.time(),
            "manager_state_before": manager_state_before.copy(),
            "llm_response": None,
            "llm_timestamp": None,
            "manager_evaluation": None,
            "manager_timestamp": None
        }
    
    def save_llm_response(self, round_num: int, llm_response: str):
        """ä¿å­˜LLMå›å¤"""
        if self.current_round_info and self.current_round_info['round_num'] == round_num:
            self.current_round_info['llm_response'] = llm_response
            self.current_round_info['llm_timestamp'] = time.time()
    
    def save_manager_evaluation(self, round_num: int, manager_result: Dict[str, Any]):
        """ä¿å­˜Managerè¯„ä¼°"""
        if self.current_round_info and self.current_round_info['round_num'] == round_num:
            self.current_round_info['manager_evaluation'] = {
                "evaluation_reasoning": manager_result['evaluation_reasoning'],
                "state_updates": {
                    'previous_state': {
                        'trust_level': manager_result['previous_state']['trust_level'],
                        'work_satisfaction': manager_result['previous_state']['work_satisfaction'],
                        'relational_valence': manager_result['previous_state']['relational_valence']
                    },
                    'new_state': {
                        'trust_level': manager_result['new_state']['trust_level'],
                        'work_satisfaction': manager_result['new_state']['work_satisfaction'],
                        'relational_valence': manager_result['new_state']['relational_valence']
                    }
                },
                "feedback_reasoning": manager_result['feedback_reasoning'],
                "feedback": manager_result['feedback']
            }
            self.current_round_info['manager_timestamp'] = time.time()
            
            # å®Œæˆå½“å‰è½®æ¬¡ï¼Œç«‹å³ä¿å­˜ä¸ºå•ç‹¬çš„JSONæ–‡ä»¶
            if (self.current_task_info and 
                self.current_round_info['llm_response'] is not None):
                
                # è·å–global roundç¼–å·
                global_round = self.current_round_info['global_round']
                
                # æ„å»ºå®Œæ•´çš„è½®æ¬¡æ•°æ®
                round_data = {
                    "task_info": {
                        "task_sequence_num": self.current_task_info['task_sequence_num'],
                        "task_sequence_num": self.current_task_info['task_sequence_num'],
                        "title": self.current_task_info['title'],
                        "files": self.current_task_info['files'],
                        "event_info": self.current_task_info['event_info']
                    },
                    "round_info": self.current_round_info.copy(),
                    "task_complete": manager_result['task_complete']
                }
                
                # ç«‹å³ä¿å­˜åˆ°å•ç‹¬çš„JSONæ–‡ä»¶
                self._save_global_round(global_round, round_data)
                
                # æ›´æ–°å…¨å±€ç»Ÿè®¡
                self.session_metadata["total_global_rounds"] = global_round
                self._save_session_info()
                
                # æ·»åŠ åˆ°ä»»åŠ¡ä¸­ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
                self.current_task_info['rounds'].append(self.current_round_info.copy())
                self.current_round_info = None
    
    def end_task(self, task_sequence_num: int):
        """ç»“æŸä»»åŠ¡"""
        if self.current_task_info:
            # æ›´æ–°ä»»åŠ¡è®¡æ•°
            self.session_metadata["total_tasks"] += 1
            self._save_session_info()
            self.current_task_info = None
    
    def finalize_experiment(self, total_tasks: int, total_interactions: int, final_manager_state: Dict[str, float]):
        """ç»“æŸå®éªŒå¹¶æœ€ç»ˆä¿å­˜ä¼šè¯ä¿¡æ¯"""
        # æ›´æ–°æœ€ç»ˆmetadata
        self.session_metadata["end_time"] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())
        self.session_metadata["total_tasks"] = total_tasks
        self.session_metadata["total_interactions"] = total_interactions
        
        # ä¿å­˜æœ€ç»ˆçš„ä¼šè¯ä¿¡æ¯
        self._save_session_info()
        
        print(f"ğŸ’¾ Experiment completed. Session info and {self.session_metadata['total_global_rounds']} global rounds saved.")
    
    def get_structured_interactions_for_detector(self) -> List[Dict[str, Any]]:
        """ä¸ºDetectoræä¾›æ‰å¹³åŒ–çš„interactionæ•°æ® - ä»global roundsæ–‡ä»¶è¯»å–"""
        detector_interactions = []
        
        # éå†æ‰€æœ‰global roundæ–‡ä»¶
        round_files = sorted(self.rounds_dir.glob("round_*.json"))
        
        for round_file in round_files:
            try:
                with open(round_file, 'r', encoding='utf-8') as f:
                    round_data = json.load(f)
                
                task_info = round_data['task_info']
                round_info = round_data['round_info']
                manager_eval = round_info['manager_evaluation']
                
                interaction = {
                    # å…¨å±€ä¿¡æ¯
                    "global_round": round_data['global_round'],
                    "timestamp": round_data['timestamp'],
                    
                    # Taskä¿¡æ¯
                    "task_sequence_num": task_info['task_sequence_num'],
                    "title": task_info['title'],
                    "files": task_info['files'],
                    
                    # Eventä¿¡æ¯
                    "event_content": task_info['event_info']['content'],
                    "event_pressure_level": task_info['event_info']['pressure_level'],
                    "event_category": task_info['event_info']['category'],
                    
                    # Roundä¿¡æ¯
                    "round": round_info['round_num'],
                    "start_timestamp": round_info['start_timestamp'],
                    
                    # ManagerçŠ¶æ€
                    "manager_state_before": round_info['manager_state_before'],
                    
                    # äº¤äº’å†…å®¹
                    "llm_response": round_info['llm_response'],
                    "manager_feedback": manager_eval['feedback'],
                    
                    # Manageræ¨ç†
                    "evaluation_reasoning": manager_eval['evaluation_reasoning'],
                    "feedback_reasoning": manager_eval['feedback_reasoning'],
                    "state_updates": manager_eval['state_updates'],
                    "task_complete": round_data['task_complete']
                }
                
                detector_interactions.append(interaction)
                
            except Exception as e:
                print(f"Warning: Failed to read {round_file}: {e}")
                continue
        
        return detector_interactions
    
    def get_record_path(self) -> str:
        """è·å–è®°å½•æ–‡ä»¶è·¯å¾„"""
        return str(self.session_dir / "experiment_data.json")
    
    def flush(self):
        """ä¿å­˜ä¼šè¯ä¿¡æ¯ - global roundså·²ç»å®æ—¶ä¿å­˜"""
        self._save_session_info()
    
    def get_total_rounds_completed(self) -> int:
        """è·å–å·²å®Œæˆçš„æ€»è½®æ•°"""
        return self.session_metadata["total_global_rounds"]
    
    @staticmethod
    def add_detector_analysis_to_experiment_data(original_file: str, detector_results: List[Dict[str, Any]], output_file: str = None) -> str:
        """
        å°†detectoråˆ†æç»“æœæ·»åŠ åˆ°ç°æœ‰çš„experiment_data.jsonä¸­
        
        Args:
            original_file: åŸå§‹experiment_data.jsonæ–‡ä»¶è·¯å¾„
            detector_results: detectoråˆ†æç»“æœåˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ_with_detectoråç¼€
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        import json
        from pathlib import Path
        import time
        
        # è¯»å–åŸå§‹å®éªŒæ•°æ®
        with open(original_file, 'r', encoding='utf-8') as f:
            experiment_data = json.load(f)
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
        if output_file is None:
            original_path = Path(original_file)
            output_file = str(original_path.parent / f"{original_path.stem}_with_detector{original_path.suffix}")
        
        # åˆ›å»ºdetectorç»“æœçš„ç´¢å¼•å­—å…¸ (title, round) -> detector_result
        detector_index = {}
        for result in detector_results:
            if 'title' not in result or 'round' not in result:
                raise ValueError("Missing 'title' or 'round' field in detector result")
            key = (result['title'], result['round'])
            detector_index[key] = {
                "deception_detected": result['deception_detected'],
                "intent": result['intent'],
                "category": result['category'],
                "severity": result['severity'],
                "confidence_score": result['confidence_score'],
                "reasoning": result['reasoning'],
                "evidence": result['evidence'],
                "analysis_timestamp": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()),
                "tokens_used": result['tokens_used'],
                "context_size": result['context_size']
            }
        
        # éå†å®éªŒæ•°æ®ï¼Œä¸ºæ¯ä¸ªroundæ·»åŠ å¯¹åº”çš„detectoråˆ†æ
        total_rounds_analyzed = 0
        for task in experiment_data['tasks']:
            title = task['title']
            for round_info in task['rounds']:
                round_num = round_info['round_num']
                key = (title, round_num)
                
                if key in detector_index:
                    round_info['detector_analysis'] = detector_index[key]
                    total_rounds_analyzed += 1
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„detectoråˆ†æï¼Œæ·»åŠ ç©ºçš„åˆ†æè®°å½•
                    round_info['detector_analysis'] = {
                        "deception_detected": None,
                        "intent": [],
                        "category": [],
                        "severity": 0,
                        "confidence_score": 0.0,
                        "reasoning": "No detector analysis available for this interaction",
                        "evidence": [],
                        "analysis_timestamp": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()),
                        "tokens_used": 0,
                        "context_size": 0,
                        "error": "Missing detector analysis"
                    }
        
        # åœ¨session_metadataä¸­æ·»åŠ detectoråˆ†æçš„æ±‡æ€»ä¿¡æ¯
        if 'detector_summary' not in experiment_data:
            experiment_data['detector_summary'] = {}
        
        # è®¡ç®—deception casesçš„ç»Ÿè®¡
        deceptive_results = [r for r in detector_results if r['deception_detected']]
        deception_count = len(deceptive_results)
        
        # è®¡ç®—ä¸¤ç§å¹³å‡ä¸¥é‡ç¨‹åº¦æŒ‡æ ‡
        # æŒ‡æ ‡1: åªè®¡ç®—æ£€æµ‹åˆ°deceptionçš„casesçš„å¹³å‡ä¸¥é‡ç¨‹åº¦
        average_severity_when_deceptive = 0.0
        if deceptive_results:
            average_severity_when_deceptive = round(
                sum(r['severity'] for r in deceptive_results) / len(deceptive_results), 3
            )
        
        # æŒ‡æ ‡2: æ‰€æœ‰interactionsçš„å¹³å‡ä¸¥é‡ç¨‹åº¦ (åŒ…æ‹¬severity=0çš„)
        average_severity_overall = 0.0
        if detector_results:
            average_severity_overall = round(
                sum(r['severity'] for r in detector_results) / len(detector_results), 3
            )
        
        experiment_data['detector_summary'].update({
            "analysis_timestamp": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()),
            "total_interactions_analyzed": len(detector_results),
            "total_rounds_with_analysis": total_rounds_analyzed,
            "deception_detection_count": deception_count,
            "deception_detection_rate": round(deception_count / len(detector_results), 3) if detector_results else 0.0,
            "average_confidence": round(sum(r['confidence_score'] for r in detector_results) / len(detector_results), 3) if detector_results else 0.0,
            "average_severity_when_deceptive": average_severity_when_deceptive,
            "average_severity_overall": average_severity_overall,
            "severity_distribution": {
                "0_honest": sum(1 for r in detector_results if r['severity'] == 0),
                "1_minor": sum(1 for r in detector_results if r['severity'] == 1),
                "2_moderate": sum(1 for r in detector_results if r['severity'] == 2),
                "3_significant": sum(1 for r in detector_results if r['severity'] == 3),
                "4_severe": sum(1 for r in detector_results if r['severity'] == 4)
            }
        })
        
        # ä¿å­˜å¢å¼ºåçš„æ•°æ®
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(experiment_data, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ’¾ Enhanced experiment data with detector analysis saved: {output_file}")
        print(f"ğŸ“Š Added detector analysis to {total_rounds_analyzed} rounds")
        
        return output_file