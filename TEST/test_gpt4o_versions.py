#!/usr/bin/env python3
"""
æµ‹è¯•æœ€æ–°çš„GPT-4oæ¨¡å‹ç‰ˆæœ¬
æ£€æŸ¥Azure OpenAIå’ŒOpenAIç›´æ¥APIçš„æœ€æ–°å¯ç”¨ç‰ˆæœ¬
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))

from core.Universal_LLM_Client import UniversalLLMClient

def load_env_file():
    """åŠ è½½.envæ–‡ä»¶"""
    env_file = project_root / '.env'
    if env_file.exists():
        with open(env_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip().strip('"').strip("'")
                    if key and value:
                        os.environ[key] = value
        print(f"âœ… Loaded .env from {env_file}")

def test_azure_gpt4o_versions():
    """æµ‹è¯•Azure OpenAI GPT-4o 2024-11-20ç‰ˆæœ¬"""
    print("\nğŸ”µ === Azure OpenAI GPT-4o 2024-11-20 æµ‹è¯• ===")
    
    config = {
        "azure_api_key": os.getenv("AZURE_API"),
        "azure_endpoint": os.getenv("AZURE_URL"),
        "azure_deployment": "gpt-4o",
        "azure_api_version": "2024-10-21",  # GAç‰ˆæœ¬
        "model_name": "gpt-4o",
        "model_version": "2024-11-20"  # æŒ‡å®šGPT-4o 2024-11-20ç‰ˆæœ¬
    }
    
    try:
        client = UniversalLLMClient("azure", config)
        
        # ç®€å•æµ‹è¯•è°ƒç”¨
        result = client.complete_chat(
            messages=[{"role": "user", "content": "What is 2+2? Answer briefly."}],
            max_tokens=20,
            temperature=0.0
        )
        
        if result['success']:
            print("âœ… Azure GPT-4o 2024-11-20 å·¥ä½œæ­£å¸¸")
            print(f"   å“åº”: {result['content']}")
            print(f"   Tokenä½¿ç”¨: {result.get('tokens_used', 'N/A')}")
        else:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {result.get('error', 'Unknown error')}")
            
    except Exception as e:
        print(f"ğŸ’¥ æµ‹è¯•å¼‚å¸¸: {str(e)}")

def test_openai_gpt4o_versions():
    """æµ‹è¯•OpenAIç›´æ¥APIçš„GPT-4oç‰ˆæœ¬"""
    print("\nğŸŸ¢ === OpenAI ç›´æ¥API GPT-4o ç‰ˆæœ¬æµ‹è¯• ===")
    
    # æµ‹è¯•ä¸åŒçš„æ¨¡å‹åç§°
    model_names = [
        "gpt-4o",              # æ ‡å‡†ç‰ˆæœ¬
        "gpt-4o-2024-05-13",   # ç‰¹å®šæ—¥æœŸç‰ˆæœ¬
        "gpt-4o-2024-08-06",   # æ›´æ–°çš„æ—¥æœŸç‰ˆæœ¬
        "gpt-4o-latest",       # æœ€æ–°ç‰ˆæœ¬åˆ«å
        "gpt-4o-mini",         # miniç‰ˆæœ¬
        "o1-mini",             # o1ç³»åˆ—mini
        "o1-preview"           # o1ç³»åˆ—é¢„è§ˆç‰ˆ
    ]
    
    for model_name in model_names:
        print(f"\nğŸ“‹ æµ‹è¯•æ¨¡å‹: {model_name}")
        
        config = {
            "api_key": os.getenv("OPENAI_API_KEY"),
            "model": model_name
        }
        
        try:
            client = UniversalLLMClient("openai", config)
            
            # å¯¹o1ç³»åˆ—ä½¿ç”¨ä¸åŒçš„å‚æ•°
            if "o1" in model_name:
                result = client.complete_chat(
                    messages=[{"role": "user", "content": "What is 2+2? Answer in one word."}],
                    max_completion_tokens=10  # o1ç³»åˆ—ä½¿ç”¨max_completion_tokens
                    # ä¸è®¾ç½®temperatureï¼Œo1ç³»åˆ—æœ‰å›ºå®šçš„temperature
                )
            else:
                result = client.complete_chat(
                    messages=[{"role": "user", "content": "What is 2+2? Answer in one word."}],
                    max_tokens=10,
                    temperature=0.0
                )
            
            if result['success']:
                print(f"âœ… æ¨¡å‹ {model_name} å·¥ä½œæ­£å¸¸")
                print(f"   å“åº”: {result['content'][:50]}")
                print(f"   Tokenä½¿ç”¨: {result.get('tokens_used', 'N/A')}")
            else:
                print(f"âŒ æ¨¡å‹ {model_name} å¤±è´¥: {result.get('error', 'Unknown error')}")
                
        except Exception as e:
            print(f"ğŸ’¥ æ¨¡å‹ {model_name} å¼‚å¸¸: {str(e)[:100]}")

def test_openrouter_versions():
    """æµ‹è¯•OpenRouterçš„æœ€æ–°æ¨¡å‹"""
    print("\nğŸ”´ === OpenRouter æœ€æ–°æ¨¡å‹æµ‹è¯• ===")
    
    model_names = [
        "google/gemini-2.5-pro",           # å½“å‰ä½¿ç”¨çš„
        "anthropic/claude-3.5-sonnet",    # Claudeæœ€æ–°
        "openai/gpt-4o",                  # OpenRouterçš„GPT-4o
        "openai/gpt-4o-2024-08-06"        # ç‰¹å®šç‰ˆæœ¬
    ]
    
    for model_name in model_names:
        print(f"\nğŸ“‹ æµ‹è¯•æ¨¡å‹: {model_name}")
        
        config = {
            "api_key": os.getenv("OPENROUTER"),
            "model": model_name
        }
        
        try:
            client = UniversalLLMClient("openrouter", config)
            
            result = client.complete_chat(
                messages=[{"role": "user", "content": "What is 2+2? Answer in one word."}],
                max_tokens=10,
                temperature=0.0
            )
            
            if result['success']:
                print(f"âœ… æ¨¡å‹ {model_name} å·¥ä½œæ­£å¸¸")
                print(f"   å“åº”: {result['content'][:50]}")
                print(f"   Tokenä½¿ç”¨: {result.get('tokens_used', 'N/A')}")
            else:
                print(f"âŒ æ¨¡å‹ {model_name} å¤±è´¥: {result.get('error', 'Unknown error')}")
                
        except Exception as e:
            print(f"ğŸ’¥ æ¨¡å‹ {model_name} å¼‚å¸¸: {str(e)[:100]}")

if __name__ == "__main__":
    print("ğŸš€ Azure OpenAI GPT-4o ç‰ˆæœ¬æµ‹è¯•å¼€å§‹")
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_env_file()
    
    # åªè¿è¡ŒAzureæµ‹è¯•
    test_azure_gpt4o_versions()
    
    print("\nâœ… Azureæµ‹è¯•å®Œæˆï¼")