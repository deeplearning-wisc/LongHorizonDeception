#!/usr/bin/env python3
"""
æµ‹è¯•Universal_LLM_Handlerçš„é•¿ä¸Šä¸‹æ–‡å¤„ç†å’Œç»­å†™åŠŸèƒ½
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import yaml
from core.Universal_LLM_Handler import UniversalLLMHandler

def load_env_file(env_path):
    """åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡"""
    env_vars = {}
    if os.path.exists(env_path):
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip().strip('"')
    return env_vars

def resolve_env_variables(config, env_vars):
    """è§£æé…ç½®ä¸­çš„ç¯å¢ƒå˜é‡"""
    if isinstance(config, dict):
        result = {}
        for key, value in config.items():
            result[key] = resolve_env_variables(value, env_vars)
        return result
    elif isinstance(config, str) and config.startswith('${') and config.endswith('}'):
        var_name = config[2:-1]
        return env_vars.get(var_name, config)
    else:
        return config

def create_random_alien_language(num_words):
    """åˆ›å»ºéšæœºå¤–æ˜Ÿè¯­è¨€"""
    import random
    import string
    
    # è®¾ç½®éšæœºç§å­ä»¥ä¾¿é‡ç°
    random.seed(42)
    
    # å¤–æ˜Ÿè¯­è¨€çš„éŸ³èŠ‚ç»„åˆ
    consonants = ['zh', 'kx', 'vl', 'qr', 'mt', 'px', 'ny', 'ws', 'gz', 'bf', 'ct', 'dj', 'fh', 'gl', 'hm', 'jk', 'lp', 'mn', 'nq', 'pr']
    vowels = ['ae', 'io', 'uu', 'ya', 'ei', 'ou', 'ax', 'iz', 'ey', 'aw', 'oy', 'ih', 'uh', 'eh']
    endings = ['xar', 'ven', 'tok', 'mar', 'din', 'kol', 'rix', 'yal', 'nem', 'qus', 'zim', 'bok', 'nil', 'wex', 'jal']
    
    words = []
    for i in range(num_words):
        # æ¯ä¸ªå¤–æ˜Ÿå•è¯ç”±1-3ä¸ªéŸ³èŠ‚ç»„æˆ
        syllables = random.randint(1, 3)
        word = ""
        for _ in range(syllables):
            word += random.choice(consonants) + random.choice(vowels)
        
        # æœ‰30%æ¦‚ç‡æ·»åŠ ç»“å°¾
        if random.random() < 0.3:
            word += random.choice(endings)
            
        words.append(word)
    
    return words

def create_massive_context_overflow():
    """åˆ›å»ºèƒ½è§¦å‘context overflowçš„è¶…å¤§è¾“å…¥ - 200,000ä¸ªéšæœºå¤–æ˜Ÿè¯­å•è¯"""
    print("Generating 200,000 random alien language words...")
    
    alien_words = create_random_alien_language(200000)
    content = " ".join(alien_words)
    
    with open('TEST/alien_massive.txt', 'w') as f:
        f.write(content)
    
    char_count = len(content)
    estimated_tokens = len(alien_words)
    
    print(f"Created alien_massive.txt:")
    print(f"  Words: {len(alien_words):,}")
    print(f"  Characters: {char_count:,}")
    print(f"  Estimated tokens: {estimated_tokens:,}")
    
    return content

def create_alien_copy_task():
    """åˆ›å»º10,000ä¸ªå¤–æ˜Ÿè¯­å•è¯ä¾›å¤åˆ¶æµ‹è¯•output continuation"""
    print("Generating 10,000 random alien language words for copy task...")
    
    alien_words = create_random_alien_language(10000)
    content = " ".join(alien_words)
    
    with open('TEST/alien_copy.txt', 'w') as f:
        f.write(content)
    
    char_count = len(content)
    estimated_tokens = len(alien_words)
    
    print(f"Created alien_copy.txt:")
    print(f"  Words: {len(alien_words):,}")
    print(f"  Characters: {char_count:,}")
    print(f"  Estimated tokens: {estimated_tokens:,}")
    
    return content

def test_gpt4o_basic_connection():
    """é¦–å…ˆæµ‹è¯•GPT-4oåŸºæœ¬è¿æ¥æ˜¯å¦æ­£å¸¸"""
    print("\n" + "="*60)
    print("PRE-TEST: GPT-4o Basic Connection Test")
    print("="*60)
    
    # åŠ è½½é…ç½®
    env_vars = load_env_file('.env')
    with open('configs/api_profiles.yaml', 'r') as f:
        config = yaml.safe_load(f)
    api_profiles = resolve_env_variables(config['api_profiles'], env_vars)
    
    # è·å–GPT-4oé…ç½®
    gpt4o_config = api_profiles['gpt4o1120azurenew']
    print(f"Testing basic connection to: {gpt4o_config['azure_endpoint']}")
    print(f"Deployment: {gpt4o_config['azure_deployment']}")
    print(f"API Version: {gpt4o_config['azure_api_version']}")
    
    try:
        # ä½¿ç”¨ä¼ ç»Ÿchat/completions APIæµ‹è¯•åŸºæœ¬è¿æ¥
        from openai import AzureOpenAI
        
        client = AzureOpenAI(
            azure_endpoint=gpt4o_config['azure_endpoint'],
            api_version=gpt4o_config['azure_api_version'],
            api_key=gpt4o_config['azure_api_key']
        )
        
        print("Attempting basic chat completion...")
        response = client.chat.completions.create(
            model=gpt4o_config['azure_deployment'],
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Say hello in one word."}
            ],
            max_tokens=10
        )
        
        print(f"âœ… GPT-4o connection SUCCESS!")
        print(f"Response: {response.choices[0].message.content}")
        return True
        
    except Exception as e:
        print(f"âŒ GPT-4o connection FAILED: {e}")
        return False

def test_gpt4o_context_overflow():
    """æµ‹è¯•GPT-4oçœŸæ­£çš„context overflow - 200,000ä¸ªå¤–æ˜Ÿè¯­å•è¯"""
    print("\n" + "="*60)
    print("TESTING GPT-4o: Context Overflow with 200K alien words")
    print("="*60)
    
    # åŠ è½½é…ç½®
    env_vars = load_env_file('.env')
    with open('configs/api_profiles.yaml', 'r') as f:
        config = yaml.safe_load(f)
    api_profiles = resolve_env_variables(config['api_profiles'], env_vars)
    
    # è·å–GPT-4oé…ç½®
    gpt4o_config = api_profiles['gpt4o1120azurenew']
    print(f"Context limit: {gpt4o_config['input_tokens']:,} tokens")
    print(f"Max output: {gpt4o_config['max_output_tokens']:,} tokens")
    
    # åˆ›å»ºhandler (verbose=True for testing)
    handler = UniversalLLMHandler("azure", gpt4o_config, verbose_print=True)
    
    # åˆ›å»ºè¶…å¤§å¤–æ˜Ÿè¯­è¾“å…¥ - 200,000ä¸ªå•è¯
    alien_input = create_massive_context_overflow()
    
    # è®¾ç½®ç³»ç»Ÿæç¤º
    handler.set_system_prompt("You are an expert translator specializing in ancient alien languages.")
    
    # è¦æ±‚å¤„ç†è¿™ä¸ªè¶…å¤§è¾“å…¥
    user_prompt = f"""I have discovered this ancient alien text containing exactly 200,000 words. Please analyze the linguistic patterns and provide a brief summary of what you observe. Here is the complete alien text:

{alien_input}

Please analyze the above alien language text and provide insights about its structure."""
    
    handler.add_user_message(user_prompt)
    
    print(f"\nTotal input tokens: ~{200000 + len(user_prompt.split()):,}")
    print("This should definitely trigger auto-truncation!")
    
    try:
        print("\n" + "-"*40)
        print("Testing context overflow handling...")
        print("-"*40)
        
        info = handler.generate_response()
        
        print("\n" + "-"*40)
        print("CONTEXT OVERFLOW TEST COMPLETED")
        print("-"*40)
        print(f"Final length: {info['final_length']:,} characters")
        
        return True
        
    except Exception as e:
        print(f"\nContext overflow test FAILED: {e}")
        return False

def test_gpt4o_output_continuation():
    """æµ‹è¯•GPT-4oçš„è¾“å‡ºç»­å†™åŠŸèƒ½ - å¤åˆ¶32,768ä¸ªå¤–æ˜Ÿè¯­å•è¯"""
    print("\n" + "="*60)
    print("TESTING GPT-4o: Output Continuation with Alien Copy Task")
    print("="*60)
    
    # åŠ è½½é…ç½®
    env_vars = load_env_file('.env')
    with open('configs/api_profiles.yaml', 'r') as f:
        config = yaml.safe_load(f)
    api_profiles = resolve_env_variables(config['api_profiles'], env_vars)
    
    # è·å–GPT-4oé…ç½®ï¼Œä½†è®¾ç½®éå¸¸å°çš„max_output_tokensæ¥å¼ºåˆ¶å¤šè½®ç»­å†™
    gpt4o_config = api_profiles['gpt4o1120azurenew'].copy()
    gpt4o_config['max_output_tokens'] = 1000  # æç«¯å°ï¼å¼ºåˆ¶å¤šè½®ç»­å†™
    
    print(f"Forced small max_output_tokens: {gpt4o_config['max_output_tokens']:,}")
    print("This should trigger output continuation!")
    
    # åˆ›å»ºhandler (verbose=True for testing)
    handler = UniversalLLMHandler("azure", gpt4o_config, verbose_print=True)
    
    # åˆ›å»º32,768ä¸ªå¤–æ˜Ÿè¯­å•è¯
    alien_copy_text = create_alien_copy_task()
    
    # è®¾ç½®ç³»ç»Ÿæç¤º
    handler.set_system_prompt("You are a precise transcription specialist. You must copy text exactly as provided, word for word, without any changes or omissions.")
    
    # è¦æ±‚ç²¾ç¡®å¤åˆ¶
    user_prompt = f"""Please copy the following alien language text EXACTLY as written, word for word. This is a sacred alien text that must be preserved perfectly. Do not translate, interpret, or modify anything - just copy it exactly:

{alien_copy_text}

Please provide the exact copy above:"""
    
    handler.add_user_message(user_prompt)
    
    print(f"\nExpected output: ~10,000 words ({len(alien_copy_text):,} characters)")
    print(f"Max output tokens set to: {gpt4o_config['max_output_tokens']:,}")
    print("This should require multiple iterations to complete!")
    
    try:
        print("\n" + "-"*40)
        print("Testing output continuation...")
        print("-"*40)
        
        info = handler.generate_response(max_iterations=5)
        
        print("\n" + "-"*40)
        print("OUTPUT CONTINUATION TEST COMPLETED")
        print("-"*40)
        print(f"Was continued: {info['was_continued']}")
        print(f"Total iterations: {info['total_iterations']}")
        print(f"Final length: {info['final_length']:,} characters")
        print(f"Response IDs: {info['response_ids']}")
        
        # æ£€æŸ¥å¤åˆ¶çš„å‡†ç¡®æ€§
        final_messages = handler.get_messages()
        assistant_response = final_messages[-1]['content']
        
        print(f"\nOriginal length: {len(alien_copy_text):,}")
        print(f"Copied length: {len(assistant_response):,}")
        
        # ç®€å•æ£€æŸ¥å‰åå‡ ä¸ªè¯æ˜¯å¦åŒ¹é…
        original_words = alien_copy_text.split()[:10]
        copied_words = assistant_response.split()[:10]
        
        print(f"First 10 words match: {original_words == copied_words}")
        print(f"Original first 10: {' '.join(original_words)}")
        print(f"Copied first 10: {' '.join(copied_words)}")
        
        # æ£€æŸ¥æœ€åå‡ ä¸ªè¯
        original_last = alien_copy_text.split()[-10:]
        copied_last = assistant_response.split()[-10:] if len(assistant_response.split()) >= 10 else assistant_response.split()
        
        print(f"\nLast 10 words match: {original_last == copied_last}")
        print(f"Original last 10: {' '.join(original_last)}")
        print(f"Copied last 10: {' '.join(copied_last)}")
        
        # æ˜¾ç¤ºå®é™…å¤åˆ¶äº†å¤šå°‘è¯
        original_word_count = len(alien_copy_text.split())
        copied_word_count = len(assistant_response.split())
        print(f"\nWord count comparison:")
        print(f"  Original: {original_word_count:,} words")
        print(f"  Copied: {copied_word_count:,} words")
        print(f"  Completion rate: {copied_word_count/original_word_count*100:.1f}%")
        
        # æ‰“å°å›å¤çš„æœ€å200å­—ç¬¦çœ‹çœ‹å®ƒåœ¨åšä»€ä¹ˆ
        print(f"\nLast 200 chars of response:")
        print(assistant_response[-200:])
        
        return info['was_continued']  # è¿”å›æ˜¯å¦å‘ç”Ÿäº†ç»­å†™
        
    except Exception as e:
        print(f"\nOutput continuation test FAILED: {e}")
        return False

def test_gpt5_basic():
    """æµ‹è¯•GPT-5çš„åŸºæœ¬æ–‡æœ¬ç”Ÿæˆ"""
    print("\n" + "="*60)
    print("TESTING GPT-5: Basic Text Generation")
    print("="*60)
    
    # åŠ è½½é…ç½®
    env_vars = load_env_file('.env')
    with open('configs/api_profiles.yaml', 'r') as f:
        config = yaml.safe_load(f)
    api_profiles = resolve_env_variables(config['api_profiles'], env_vars)
    
    # è·å–GPT-5é…ç½®
    gpt5_config = api_profiles['gpt5_azure']
    print(f"Using GPT-5 config:")
    print(f"  Deployment: {gpt5_config['azure_deployment']}")
    print(f"  Input tokens limit: {gpt5_config['input_tokens']:,}")
    print(f"  Max output tokens: {gpt5_config['max_output_tokens']:,}")
    
    # åˆ›å»ºhandler (verbose=True for testing)
    handler = UniversalLLMHandler("azure", gpt5_config, verbose_print=True)
    
    # è®¾ç½®ç³»ç»Ÿæç¤º
    handler.set_system_prompt("You are a helpful assistant.")
    
    # ç®€å•çš„ç”¨æˆ·æ¶ˆæ¯
    handler.add_user_message("Write a brief 200-word summary about the benefits of artificial intelligence in business.")
    
    try:
        print("\n" + "-"*40)
        print("Starting GPT-5 generation...")
        print("-"*40)
        
        info = handler.generate_response()
        
        print("\n" + "-"*40)
        print("GPT-5 GENERATION COMPLETED")
        print("-"*40)
        print(f"Was continued: {info['was_continued']}")
        print(f"Total iterations: {info['total_iterations']}")
        print(f"Final length: {info['final_length']:,} characters")
        
        # è·å–å›å¤
        final_messages = handler.get_messages()
        assistant_response = final_messages[-1]['content']
        
        print(f"\nGPT-5 Response:")
        print("-" * 50)
        print(assistant_response)
        print("-" * 50)
        
        return True
        
    except Exception as e:
        print(f"\nGPT-5 test FAILED: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("Starting Universal_LLM_Handler EXTREME STRESS TESTS")
    print("=" * 80)
    
    # é¦–å…ˆæµ‹è¯•GPT-4oåŸºæœ¬è¿æ¥
    gpt4o_connection = test_gpt4o_basic_connection()
    if not gpt4o_connection:
        print("âŒ GPT-4o basic connection failed, skipping advanced tests")
        return
    
    # æµ‹è¯•çœŸæ­£çš„context overflow - 200,000ä¸ªå¤–æ˜Ÿè¯­å•è¯
    context_overflow = test_gpt4o_context_overflow()
    
    # æµ‹è¯•è¾“å‡ºç»­å†™åŠŸèƒ½ - 32,768ä¸ªå¤–æ˜Ÿè¯­å•è¯å¤åˆ¶
    output_continuation = test_gpt4o_output_continuation()
    
    # æµ‹è¯•GPT-5åŸºæœ¬åŠŸèƒ½
    gpt5_success = test_gpt5_basic()
    
    # ç»“æœæ±‡æ€»
    print("\n" + "="*80)
    print("EXTREME STRESS TEST RESULTS")
    print("="*80)
    print(f"GPT-4o Basic Connection: {'PASS' if gpt4o_connection else 'FAIL'}")
    print(f"GPT-4o Context Overflow (200K words): {'PASS' if context_overflow else 'FAIL'}")
    print(f"GPT-4o Output Continuation (32K words): {'PASS' if output_continuation else 'FAIL'}")
    print(f"GPT-5 Basic Test: {'PASS' if gpt5_success else 'FAIL'}")
    
    total_tests = 4
    passed_tests = sum([gpt4o_connection, context_overflow, output_continuation, gpt5_success])
    
    if passed_tests == total_tests:
        print(f"\nğŸ‰ ALL {total_tests} EXTREME TESTS PASSED!")
        print("Universal_LLM_Handler can handle:")
        print("  âœ… Massive context overflow (200K+ tokens)")
        print("  âœ… Auto-truncation of old messages") 
        print("  âœ… Multi-iteration output continuation")
        print("  âœ… Both GPT-4o and GPT-5 models")
    else:
        print(f"\nâš ï¸  {passed_tests}/{total_tests} tests passed. Check failures above.")
        if context_overflow and output_continuation:
            print("âœ… Core auto-truncation and continuation features working!")
        if not output_continuation:
            print("âš ï¸  Output continuation may need adjustment - check max_output_tokens setting")

if __name__ == "__main__":
    main()