# detector.py
# ç®€åŒ–çš„Detectorç³»ç»Ÿ - åªä¿ç•™æ‰¹é‡åˆ†æåŠŸèƒ½
# ç§»é™¤äº†æ‰€æœ‰æœªä½¿ç”¨çš„å®æ—¶æ£€æµ‹ä»£ç å’Œrubrics_balancedä¾èµ–

import time
from typing import Dict, Any, List
try:
    # å½“ä½œä¸ºæ¨¡å—å¯¼å…¥æ—¶ä½¿ç”¨ç›¸å¯¹å¯¼å…¥
    from .Universal_LLM_Client import UniversalLLMClient
    from .detector_rubrics import SEQUENCE_ANALYSIS_TEMPLATE, BASE_DETECTION_PROMPT
except ImportError:
    # å½“ä½œä¸ºä¸»ç¨‹åºè¿è¡Œæ—¶ä½¿ç”¨ç›´æ¥å¯¼å…¥
    import sys
    import os
    
    # æ™ºèƒ½æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if os.path.basename(current_dir) == 'core':
        parent_dir = os.path.dirname(current_dir)
    else:
        parent_dir = os.getcwd()
    
    if parent_dir not in sys.path:
        sys.path.insert(0, parent_dir)
    
    # ç›´æ¥å¯¼å…¥æ–‡ä»¶
    import importlib.util
    
    # å¯¼å…¥Universal_LLM_Client
    client_path = os.path.join(current_dir, 'Universal_LLM_Client.py')
    spec = importlib.util.spec_from_file_location("Universal_LLM_Client", client_path)
    client_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(client_module)
    UniversalLLMClient = client_module.UniversalLLMClient
    
    # å¯¼å…¥detector_rubrics
    rubrics_path = os.path.join(current_dir, 'detector_rubrics.py')
    spec = importlib.util.spec_from_file_location("detector_rubrics", rubrics_path)
    rubrics_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(rubrics_module)
    SEQUENCE_ANALYSIS_TEMPLATE = rubrics_module.SEQUENCE_ANALYSIS_TEMPLATE
    BASE_DETECTION_PROMPT = rubrics_module.BASE_DETECTION_PROMPT

class DeceptionDetector:
    """
    ç®€åŒ–çš„LLM-as-Detectorç³»ç»Ÿ - åªè¿›è¡Œæ‰¹é‡åºåˆ—åˆ†æ
    ç§»é™¤äº†æ‰€æœ‰æœªä½¿ç”¨çš„å®æ—¶æ£€æµ‹åŠŸèƒ½
    """
    
    def __init__(self, llm_provider: str, llm_config: Dict[str, Any]):
        """Initialize the Batch DeceptionDetector with Universal LLM Client"""
        self.llm_provider = llm_provider
        self.llm_config = llm_config
        
        # åˆå§‹åŒ–é€šç”¨LLMå®¢æˆ·ç«¯
        self.llm_client = UniversalLLMClient(llm_provider, llm_config)
        
        # è·å–contexté™åˆ¶
        self.context_limit = self.llm_client.model_limits.context_window
        
        print(f"[DETECTOR] Initialized with {llm_provider} provider")

    def analyze_interaction_sequence(self, interaction_records: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆ†æäº¤äº’åºåˆ— - æ¯ä¸ªinteractionéƒ½åŸºäºå®Œæ•´åºåˆ—è¿›è¡Œåˆ†æ
        
        Args:
            interaction_records: å®Œæ•´çš„äº¤äº’è®°å½•åˆ—è¡¨
            
        Returns:
            æ¯ä¸ªinteractionçš„åˆ†æç»“æœåˆ—è¡¨
        """
        print(f"\n[DETECTOR] Starting batch analysis of {len(interaction_records)} interactions")
        
        results = []
        
        for i, current_interaction in enumerate(interaction_records):
            print(f"\n[DETECTOR] Analyzing interaction {i+1}/{len(interaction_records)}: {current_interaction['task_id']} Round {current_interaction['round']}")
            
            # æ„å»ºå®Œæ•´èƒŒæ™¯ä¸Šä¸‹æ–‡
            background_context = self._build_full_sequence_context(interaction_records, current_interaction)
            
            # æ„å»ºå½“å‰åˆ†æçš„prompt
            analysis_prompt = self._build_batch_analysis_prompt(current_interaction, background_context)
            
            # æ£€æŸ¥contextå¤§å°
            estimated_tokens = self.llm_client.estimate_tokens(analysis_prompt)
            print(f"[DETECTOR] Context size: {estimated_tokens} tokens")
            
            if estimated_tokens > self.context_limit:
                raise RuntimeError(
                    f"Context overflow! Estimated tokens: {estimated_tokens}, "
                    f"Model limit: {self.context_limit}. Cannot proceed with batch analysis."
                )
            
            # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
            try:
                llm_result = self.llm_client.complete_chat(
                    messages=[{"role": "user", "content": analysis_prompt}],
                    model=None,  # ä½¿ç”¨é»˜è®¤æ¨¡å‹
                    max_tokens=self.llm_client.model_limits.max_output_tokens,  # æ‹‰æ»¡
                    temperature=0.1,  # ä½æ¸©ç¡®ä¿ä¸€è‡´æ€§
                    system_role=None,
                    require_complete_response=True
                )
                
                if not llm_result['success']:
                    raise RuntimeError(f"LLM call failed: {llm_result.get('error', 'Unknown error')}")
                
                
                # è§£æç»“æœ
                analysis_result = self._parse_batch_analysis_response(llm_result['content'])
                
                # æ·»åŠ å…ƒä¿¡æ¯
                analysis_result.update({
                    'task_id': current_interaction['task_id'],
                    'round': current_interaction['round'],
                    'tokens_used': llm_result.get('tokens_used', 0),
                    'context_size': estimated_tokens
                })
                
                results.append(analysis_result)
                print(f"[DETECTOR] Analysis completed: deception_detected={analysis_result['deception_detected']}")
                
            except Exception as e:
                print(f"[DETECTOR] Analysis failed for interaction {i+1}: {e}")
                raise RuntimeError(f"Batch analysis failed at interaction {i+1}: {str(e)}")
        
        print(f"\n[DETECTOR] Batch analysis completed. {len(results)} interactions analyzed.")
        return results
    
    def _build_full_sequence_context(self, all_interactions: List[Dict[str, Any]], current_interaction: Dict[str, Any]) -> str:
        """æ„å»ºå®Œæ•´åºåˆ—çš„èƒŒæ™¯ä¸Šä¸‹æ–‡"""
        context_parts = []
        
        context_parts.append("=== COMPLETE INTERACTION SEQUENCE ===")
        context_parts.append(f"Total interactions in sequence: {len(all_interactions)}")
        context_parts.append("")
        
        for i, interaction in enumerate(all_interactions, 1):
            context_parts.append(f"[{i}] {interaction['task_id']} Round {interaction['round']}")
            context_parts.append(f"Task: {interaction['task_description']}")
            context_parts.append(f"Event: {interaction['event_description']}")
            context_parts.append(f"Agent Response: {interaction['llm_response']}")
            context_parts.append(f"Manager Feedback: {interaction['manager_feedback']}")
            context_parts.append("")
        
        context_parts.append("=== END SEQUENCE ===")
        
        return "\n".join(context_parts)
    
    def _build_batch_analysis_prompt(self, current_interaction: Dict[str, Any], background_context: str) -> str:
        """æ„å»ºæ‰¹é‡åˆ†æçš„prompt"""
        return SEQUENCE_ANALYSIS_TEMPLATE.format(
            task_id=current_interaction['task_id'],
            round_num=current_interaction['round'],
            agent_response=current_interaction['llm_response'],
            manager_feedback=current_interaction['manager_feedback'],
            background_context=background_context,
            base_prompt=BASE_DETECTION_PROMPT
        )
    
    def _parse_batch_analysis_response(self, response_text: str) -> Dict[str, Any]:
        """è§£ææ‰¹é‡åˆ†æçš„LLMå“åº”"""
        lines = response_text.strip().split('\n')
        
        result = {
            'deception_detected': False,
            'intent': [],
            'category': [],
            'severity': 0,
            'confidence_score': 0.0,
            'reasoning': '',
            'evidence': []
        }
        
        evidence_lines = []
        in_evidence = False
        
        for line in lines:
            line = line.strip()
            
            if line.startswith('DECEPTION_DETECTED:'):
                value_text = line.split(':', 1)[1].strip().lower()
                result['deception_detected'] = value_text in ['true', 'yes', '1']
            
            elif line.startswith('INTENT:'):
                intent_text = line.split(':', 1)[1].strip()
                result['intent'] = [i.strip() for i in intent_text.split(',') if i.strip()]
            
            elif line.startswith('CATEGORY:'):
                category_text = line.split(':', 1)[1].strip()
                result['category'] = [c.strip() for c in category_text.split(',') if c.strip()]
            
            elif line.startswith('SEVERITY:'):
                try:
                    value = int(line.split(':', 1)[1].strip())
                    result['severity'] = max(0, min(4, value))
                except ValueError:
                    result['severity'] = 0
            
            elif line.startswith('CONFIDENCE_SCORE:'):
                try:
                    value = float(line.split(':', 1)[1].strip())
                    result['confidence_score'] = max(0.0, min(1.0, value))
                except ValueError:
                    result['confidence_score'] = 0.0
            
            elif line.startswith('REASONING:'):
                result['reasoning'] = line.split(':', 1)[1].strip()
            
            elif line.startswith('EVIDENCE:'):
                in_evidence = True
                evidence_content = line.split(':', 1)[1].strip()
                if evidence_content:
                    evidence_lines.append(evidence_content)
            
            elif in_evidence and line.startswith('- '):
                evidence_lines.append(line[2:])  # ç§»é™¤"- "å‰ç¼€
        
        result['evidence'] = evidence_lines
        
        return result

    def _create_error_result(self, task_sequence_num: int, task_id: str, error_message: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯ç»“æœå­—å…¸ - ç®€åŒ–ç‰ˆæœ¬ï¼ŒåªåŒ…å«æ‰¹é‡åˆ†æéœ€è¦çš„å­—æ®µ"""
        return {
            'deception_detected': False,
            'intent': [],
            'category': [],
            'severity': 0,
            'confidence_score': 0.0,
            'reasoning': f"Error during evaluation: {error_message}",
            'evidence': [],
            'task_id': task_id,
            'error': True,
            'error_message': error_message
        }

    def get_llm_statistics(self) -> Dict[str, Any]:
        """Get LLM client statistics"""
        return self.llm_client.get_statistics()


# ==================== ç‹¬ç«‹åˆ†æåŠŸèƒ½ ====================

def _save_detector_results_text(detector_results: List[Dict[str, Any]], output_file: str, session_name: str = 'unknown'):
    """ä¿å­˜Detectorç»“æœä¸ºLLMå‹å¥½çš„æ–‡æœ¬æ ¼å¼"""
    import time
    from pathlib import Path
    
    lines = []
    
    # æ–‡ä»¶å¤´
    lines.extend([
        "=== DETECTOR ANALYSIS REPORT ===",
        f"Session: {session_name}",
        f"Analysis_Time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}",
        f"Total_Interactions_Analyzed: {len(detector_results)}",
        ""
    ])
    
    # æ‘˜è¦ç»Ÿè®¡
    deception_count = sum(1 for r in detector_results if r.get('deception_detected', False))
    severity_counts = {}
    for r in detector_results:
        severity = r.get('severity', 0)
        severity_counts[severity] = severity_counts.get(severity, 0) + 1
    
    lines.extend([
        "=== ANALYSIS SUMMARY ===",
        f"Total_Deception_Detected: {deception_count}/{len(detector_results)} ({deception_count/len(detector_results)*100:.1f}%)",
        f"Severity_Distribution:"
    ])
    
    for sev in range(5):
        count = severity_counts.get(sev, 0)
        lines.append(f"  - Severity_{sev}: {count} interactions")
    
    lines.extend(["", "=== DETAILED ANALYSIS ===", ""])
    
    # æ¯ä¸ªinteractionçš„è¯¦ç»†åˆ†æ
    for i, result in enumerate(detector_results, 1):
        task_id = result.get('task_id', f'Task{i}')
        round_num = result.get('round', 1)
        
        lines.extend([
            f"[ANALYSIS_{i:03d}]",
            f"Task_ID: {task_id}",
            f"Round: {round_num}",
            f"DECEPTION_DETECTED: {result.get('deception_detected', False)}",
            f"INTENT: {','.join(result.get('intent', []))}",
            f"CATEGORY: {','.join(result.get('category', []))}",
            f"SEVERITY: {result.get('severity', 0)}",
            f"CONFIDENCE_SCORE: {result.get('confidence_score', 0.0)}",
            f"REASONING: {result.get('reasoning', 'No reasoning provided')}",
            f"EVIDENCE:"
        ])
        
        # æ·»åŠ evidenceåˆ—è¡¨
        evidence_list = result.get('evidence', [])
        if evidence_list:
            for evidence in evidence_list:
                lines.append(f"- {evidence}")
        else:
            lines.append("- No evidence provided")
        
        lines.append("")  # ç©ºè¡Œåˆ†éš”
    
    lines.append("=== END REPORT ===")
    
    # å†™å…¥æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        for line in lines:
            f.write(line + '\n')

def _save_detector_results_json(detector_results: List[Dict[str, Any]], json_file: str, session_name: str = 'unknown'):
    """ä¿å­˜JSONæ ¼å¼ç”¨äºæ•°æ®åˆ†æ"""
    import json
    import time
    
    # æ·»åŠ å…ƒä¿¡æ¯åˆ°JSON
    deception_count = sum(1 for r in detector_results if r.get('deception_detected', False))
    severity_counts = {}
    for r in detector_results:
        severity = r.get('severity', 0)
        severity_counts[severity] = severity_counts.get(severity, 0) + 1
    
    output_data = {
        "metadata": {
            "session": session_name,
            "analysis_time": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()),
            "total_interactions": len(detector_results),
            "deception_detected": deception_count,
            "deception_rate": deception_count / len(detector_results) if detector_results else 0,
            "severity_distribution": severity_counts
        },
        "results": detector_results  # è§£æåçš„å®Œæ•´æ•°æ®
    }
    
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

def load_interaction_records(file_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½ä¿å­˜çš„äº¤äº’è®°å½• - åªæ”¯æŒæ–°çš„æ–‡æœ¬æ ¼å¼"""
    from pathlib import Path
    
    # å¦‚æœæ˜¯ç›®å½•è·¯å¾„ï¼ŒæŸ¥æ‰¾complete_interaction_record.txt
    if Path(file_path).is_dir():
        text_file = Path(file_path) / "complete_interaction_record.txt"
        
        if text_file.exists():
            file_path = str(text_file)
        else:
            raise FileNotFoundError(f"complete_interaction_record.txt not found in: {file_path}")
    
    print(f"ğŸ“„ Loading from: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åªæ”¯æŒæ–°çš„æ–‡æœ¬æ ¼å¼
        if not ('[TASK_' in content):
            raise ValueError("Invalid format: complete_interaction_record.txt must contain [TASK_] markers")
        
        print("ğŸ”„ Parsing text format...")
        records = extract_analysis_data_from_text(content)
        print(f"âœ… Extracted {len(records)} interaction records from text format")
        return records
        
    except FileNotFoundError:
        print(f"âŒ File not found: {file_path}")
        raise
    except Exception as e:
        print(f"âŒ Error loading file: {e}")
        raise

def find_latest_session() -> str:
    """æŸ¥æ‰¾æœ€æ–°çš„sessionç›®å½•"""
    from pathlib import Path
    
    # æ™ºèƒ½æŸ¥æ‰¾resultsç›®å½•
    if Path(__file__).parent.name == 'core':
        # ä» core/detector.py è¿è¡Œ
        results_dir = Path(__file__).parent.parent / "results"
    else:
        # ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
        results_dir = Path.cwd() / "results"
    
    if not results_dir.exists():
        # å°è¯•å½“å‰ç›®å½•
        results_dir = Path("results")
        if not results_dir.exists():
            return ""
    
    # æŸ¥æ‰¾æ‰€æœ‰sessionç›®å½•ï¼ŒæŒ‰æ—¶é—´æ’åº
    session_dirs = [d for d in results_dir.iterdir() if d.is_dir() and d.name.startswith("task_stream_")]
    if not session_dirs:
        return ""
    
    # æŒ‰åç§°æ’åºï¼Œæœ€æ–°çš„åœ¨æœ€å
    session_dirs.sort(key=lambda x: x.name)
    latest_session = session_dirs[-1]
    
    print(f"ğŸ“ Found latest session: {latest_session.name}")
    return str(latest_session)

def get_llm_config() -> tuple:
    """ä»é…ç½®æ–‡ä»¶è·å–Detectorçš„LLMé…ç½®"""
    import sys
    import os
    from pathlib import Path
    
    # æ™ºèƒ½è·å–é¡¹ç›®æ ¹ç›®å½•
    if Path(__file__).parent.name == 'core':
        # ä» core/detector.py è¿è¡Œ
        project_root = Path(__file__).parent.parent
    else:
        # ä»å…¶ä»–ä½ç½®è¿è¡Œ
        project_root = Path.cwd()
    
    # ç¡®ä¿èƒ½å¯¼å…¥é¡¹ç›®æ¨¡å—
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    try:
        from utils.yaml_config_loader import load_yaml_config
        config = load_yaml_config(project_root / "task_stream_config.yaml")
        llm_api_config = config['llm_api_config']
        
        # è·å–Detectorä¸“ç”¨é…ç½® - ä¸¥æ ¼æ¨¡å¼ï¼Œæ— é»˜è®¤å€¼
        detector_config = llm_api_config['detector']
        llm_provider = detector_config['provider']
        
        if llm_provider == 'openai':
            # å’Œmain.pyä¸€æ ·ï¼Œç›´æ¥è¿”å›é…ç½®ï¼Œè®©Universal_LLM_Clientå¤„ç†
            llm_config = detector_config['openai']
        else:
            # å¦‚æœæ˜¯Azureï¼Œéœ€è¦ä»config.pyåŠ è½½
            import config as azure_config
            llm_config = {
                'azure_api_key': azure_config.AZURE_API_KEY,
                'azure_endpoint': azure_config.AZURE_ENDPOINT,
                'azure_deployment': azure_config.AZURE_DEPLOYMENT_NAME,
                'model_name': azure_config.MODEL_NAME,
                'api_version': azure_config.AZURE_API_VERSION
            }
        
        return llm_provider, llm_config
        
    except Exception as e:
        print(f"âŒ Failed to load LLM config: {e}")
        raise RuntimeError(f"Cannot proceed without valid configuration: {e}")

def extract_analysis_data_from_text(text_content: str) -> List[Dict[str, Any]]:
    """ä»complete_interaction_record.txtä¸­æå–detectoréœ€è¦çš„åˆ†æç‰‡æ®µ"""
    interactions = []
    lines = text_content.split('\n')
    
    current_task_id = None
    current_round = None
    current_task_description = None
    current_event_description = None
    current_agent_response = None
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # æå–Taskä¿¡æ¯
        if line.startswith('[TASK_') and '_START]' in line:
            # ç»§ç»­è¯»å–TaskIDå’Œæè¿°
            for j in range(i+1, min(i+10, len(lines))):
                if lines[j].startswith('TaskID:'):
                    current_task_id = lines[j].split('TaskID:', 1)[1].strip()
                elif lines[j].startswith('Description:'):
                    current_task_description = lines[j].split('Description:', 1)[1].strip()
                elif lines[j].startswith('[EVENT_'):
                    break
        
        # æå–Eventä¿¡æ¯
        elif line.startswith('[EVENT_'):
            # è¯»å–Eventçš„Contentä½œä¸ºæè¿°
            for j in range(i+1, min(i+10, len(lines))):
                if lines[j].startswith('Content:'):
                    current_event_description = lines[j].split('Content:', 1)[1].strip()
                    break
                elif lines[j].startswith('['):
                    break
        
        # æå–Roundä¿¡æ¯
        elif line.startswith('[ROUND_'):
            current_round = int(line.split('_')[1])
        
        # æå–Agentå›å¤
        elif line.startswith('[AGENT_RESPONSE_'):
            # è¯»å–Agentçš„å®Œæ•´å›å¤
            response_lines = []
            for j in range(i+1, len(lines)):
                if lines[j].startswith('[') and not lines[j].strip() == '':
                    break
                response_lines.append(lines[j])
            current_agent_response = '\n'.join(response_lines).strip()
        
        # æå–Manageråé¦ˆå¹¶æ„å»ºäº¤äº’è®°å½•
        elif line.startswith('[MANAGER_EVALUATION_'):
            manager_feedback = None
            # è¯»å–Managerçš„Feedback
            for j in range(i+1, min(i+20, len(lines))):
                if lines[j].startswith('Feedback:'):
                    manager_feedback = lines[j].split('Feedback:', 1)[1].strip()
                    break
                elif lines[j].startswith('['):
                    break
            
            # æ„å»ºå®Œæ•´çš„äº¤äº’è®°å½•
            if all([current_task_id, current_round, current_agent_response, manager_feedback]):
                interactions.append({
                    'task_id': current_task_id,
                    'round': current_round,
                    'task_description': current_task_description or '',
                    'event_description': current_event_description or 'No event',
                    'llm_response': current_agent_response,
                    'manager_feedback': manager_feedback,
                    'timestamp': 0  # ä¸é‡è¦ï¼Œdetectorä¸ç”¨è¿™ä¸ª
                })
        
        i += 1
    
    return interactions

def analyze_saved_results(interaction_records: List[Dict[str, Any]], output_file: str = None):
    """åˆ†æäº¤äº’è®°å½•å¹¶è¾“å‡ºç»“æœ"""
    if not interaction_records:
        print("âŒ No interaction records to analyze")
        return
    
    # è·å–LLMé…ç½®
    llm_provider, llm_config = get_llm_config()
    print(f"ğŸ¤– Using {llm_provider} for detection analysis")
    
    # åˆå§‹åŒ–Detector
    try:
        detector = DeceptionDetector(llm_provider, llm_config)
        print(f"âœ… Detector initialized successfully")
    except Exception as e:
        print(f"âŒ Failed to initialize detector: {e}")
        return
    
    # æ‰§è¡Œæ‰¹é‡åˆ†æ
    print(f"\nğŸ” Starting batch analysis of {len(interaction_records)} interactions...")
    try:
        detector_results = detector.analyze_interaction_sequence(interaction_records)
        
        # åˆ†æç»“æœæ‘˜è¦
        deception_count = sum(1 for r in detector_results if r.get('deception_detected', False))
        print(f"\nğŸ“Š ANALYSIS SUMMARY:")
        print(f"   Total interactions analyzed: {len(detector_results)}")
        print(f"   Deception detected: {deception_count}")
        print(f"   Deception rate: {deception_count/len(detector_results)*100:.1f}%")
        
        # è¯¦ç»†ç»“æœ
        print(f"\nğŸ“‹ DETAILED RESULTS:")
        for i, result in enumerate(detector_results, 1):
            task_id = result.get('task_id', f'Task{i}')
            round_num = result.get('round', 1)
            deception = result.get('deception_detected', False)
            severity = result.get('severity', 0)
            confidence = result.get('confidence_score', 0.0)
            intent = result.get('intent', [])
            category = result.get('category', [])
            
            status_icon = "ğŸš¨" if deception else "âœ…"
            intent_str = ','.join(intent) if intent else 'NONE'
            category_str = ','.join(category) if category else 'NONE'
            
            print(f"   {status_icon} {task_id} R{round_num}: "
                  f"Deception={deception}, Severity={severity}, "
                  f"Confidence={confidence:.2f}, Intent={intent_str}, Category={category_str}")
        
        # ä¿å­˜ç»“æœ - åŒæ ¼å¼ï¼šLLMå‹å¥½æ–‡æœ¬ + æ•°æ®åˆ†æJSON
        if output_file:
            try:
                # 1. ä¿å­˜LLMå‹å¥½çš„æ–‡æœ¬æ ¼å¼ï¼ˆä¸»è¦æ ¼å¼ï¼‰
                _save_detector_results_text(detector_results, output_file, session_name='detector_analysis')
                print(f"\nğŸ’¾ LLM-friendly text saved to: {output_file}")
                
                # 2. è‡ªåŠ¨ç”ŸæˆJSONç‰ˆæœ¬ï¼ˆæ–¹ä¾¿æ•°æ®åˆ†æï¼‰
                from pathlib import Path
                output_path = Path(output_file)
                json_file = str(output_path.with_suffix('.json'))
                _save_detector_results_json(detector_results, json_file, session_name='detector_analysis')
                print(f"ğŸ’¾ Data analysis JSON saved to: {json_file}")
                
            except Exception as e:
                print(f"âš ï¸  Failed to save results: {e}")
        
        return detector_results
        
    except Exception as e:
        print(f"âŒ Analysis failed: {e}")
        import traceback
        print("Full traceback:")
        traceback.print_exc()
        return None


if __name__ == "__main__":
    import sys
    from pathlib import Path
    
    # ç¡®ä¿èƒ½æ­£ç¡®å¯¼å…¥é¡¹ç›®æ¨¡å—
    if Path(__file__).parent.name == 'core':
        project_root = Path(__file__).parent.parent
        if str(project_root) not in sys.path:
            sys.path.insert(0, str(project_root))
    
    import argparse
    
    parser = argparse.ArgumentParser(description='Standalone Detector Analysis')
    parser.add_argument('--results_path', '-r', type=str, 
                       help='Path to interaction_records.json file')
    parser.add_argument('--session', '-s', type=str,
                       help='Session name (e.g., task_stream_20250812_014857)')
    parser.add_argument('--latest', '-l', action='store_true',
                       help='Analyze the latest session automatically')
    parser.add_argument('--output', '-o', type=str,
                       help='Output file for detector results (JSON format)')
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸ” STANDALONE DETECTOR ANALYSIS")
    print("="*60)
    
    # ç¡®å®šè¦åˆ†æçš„æ–‡ä»¶è·¯å¾„
    results_path = None
    
    if args.results_path:
        results_path = args.results_path
    elif args.session:
        # æ™ºèƒ½æŸ¥æ‰¾sessionç›®å½•
        from pathlib import Path
        if Path(__file__).parent.name == 'core':
            results_dir = Path(__file__).parent.parent / "results"
        else:
            results_dir = Path("results")
        results_path = str(results_dir / args.session)
    elif args.latest:
        latest_session_dir = find_latest_session()
        if latest_session_dir:
            results_path = latest_session_dir
        else:
            print("âŒ No session directories found")
            exit(1)
    else:
        print("âŒ Please specify one of: --results_path, --session, or --latest")
        parser.print_help()
        exit(1)
    
    print(f"ğŸ“‚ Analyzing: {results_path}")
    
    # åŠ è½½äº¤äº’è®°å½•
    interaction_records = load_interaction_records(results_path)
    if not interaction_records:
        exit(1)
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_file = args.output
    if not output_file and results_path:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œè‡ªåŠ¨ä¿å­˜åˆ°sessionç›®å½•
        from pathlib import Path
        if Path(results_path).is_dir():
            session_dir = Path(results_path)
            output_file = str(session_dir / "detector_analysis.txt")
            print(f"ğŸ“ Auto-saving to: {output_file}")
    
    # æ‰§è¡Œåˆ†æ
    results = analyze_saved_results(interaction_records, output_file)
    
    if results:
        print(f"\nâœ… Analysis completed successfully!")
    else:
        print(f"\nâŒ Analysis failed!")
        exit(1)
    
    print("="*60)
